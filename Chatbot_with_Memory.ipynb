{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TplHAzzQ_k81"
      },
      "source": [
        "# Chatbot with Memory\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adDLNsW56YWS"
      },
      "source": [
        "### Basic Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Q2V8Z9VMm5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94df0c2c-d55f-4b77-f5aa-81f3202d810a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain-openai langchain-together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbA9knJEiPi9"
      },
      "source": [
        "- Get OpenAI API key: https://platform.openai.com/account/api-keys\n",
        "- Get Together AI API key: https://api.together.xyz/settings/api-keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hf6OmfQjgEWm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "os.environ['TOGETHER_API_KEY'] = \"f06917675018c9d0ca2fde2c8c5af952832bebdf121938bb51da6486d4115ebf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kopsuc39uhkD"
      },
      "outputs": [],
      "source": [
        "# Using OpenAI Models\n",
        "from langchain_openai import ChatOpenAI\n",
        "gpt4o_mini_model = ChatOpenAI(model = \"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2yjLXjDy0WN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dmFJ9nAzGuWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "626fe8d6-b5d9-4a9e-a490-20c5cd5ad321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the scarecrow win an award? \n",
            "\n",
            "Because he was outstanding in his field!\n"
          ]
        }
      ],
      "source": [
        "response = gpt4o_mini_model.invoke('Tell me a short joke')\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = gpt4o_mini_model.invoke('Who was the first black president of USA?')\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "oVCcWm9bTtDp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9762f1f6-7026-46d8-b904-bedd4a639dac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first Black president of the United States was Barack Obama. He served as the 44th president from January 20, 2009, to January 20, 2017.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = gpt4o_mini_model.invoke('What is his birthday?')\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "OqQBwr6MT837",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d389ee-2c73-4b0d-f98b-c1ae7fac3cc1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I need more context to provide an answer. Whose birthday are you referring to?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-iQJcvJf9SSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a Llama Model with Together AI! [CLASSWORK]\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llama_model = ChatOpenAI(model = \"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "                      openai_api_key = \"f06917675018c9d0ca2fde2c8c5af952832bebdf121938bb51da6486d4115ebf\", ## use your key\n",
        "                      openai_api_base = \"https://api.together.xyz/v1\")"
      ],
      "metadata": {
        "id": "Q02Pe_UQTtyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llama_model.invoke(\"Tell me a joke\")\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "M_lKVin2tZZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnF5JbSe-h4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory"
      ],
      "metadata": {
        "id": "YjYAz06SUVVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt4o_mini_model = ChatOpenAI(model = \"gpt-4o-mini\")\n",
        "# memory = ConversationBufferMemory(k = 3)\n",
        "memory = ConversationSummaryMemory()\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=gpt4o_mini_model,\n",
        "    memory = memory\n",
        ")"
      ],
      "metadata": {
        "id": "ru53hAE6UVR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = conversation.predict(input = 'Who was the first black president of USA?')\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Oe0uRZcxUVNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = conversation.predict(input = 'When was his birthday?')\n",
        "print(response)"
      ],
      "metadata": {
        "id": "WJr8Yk-XUsLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kGkiydlG_LX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nj-TDLug_bnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0MLzVSE7_LSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = gpt4o_mini_model.invoke('Tell me a short joke')\n",
        "\n",
        "response"
      ],
      "metadata": {
        "id": "wfkgHbJ3UsC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = gpt4o_mini_model.invoke('What is your name?')\n",
        "\n",
        "response"
      ],
      "metadata": {
        "id": "AThN2s3XVQvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "15QjTf1XVQqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqe7RIFQHBxo"
      },
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYMpb5gDNVG3"
      },
      "source": [
        "### Human and AI Messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrR-jRbbHcAB"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gpt4o_mini_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "messages = [HumanMessage(content=\"Tell me a short joke\")]\n",
        "\n",
        "response = gpt4o_mini_model.invoke(messages)\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nbg0NWjNMuh"
      },
      "source": [
        "### Working with System Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RxZl4RXQlen"
      },
      "source": [
        "\n",
        "```python\n",
        "System messages in AI conversations provide essential context and instructions to guide the AI's behavior. They can be categorized into four types:\n",
        "\n",
        "Role definitions: These establish the AI's persona or expertise.\n",
        "Example: \"You are a professional chef specializing in Italian cuisine.\"\n",
        "Task-specific instructions: These outline the specific actions or approaches the AI should take.\n",
        "Example: \"Provide step-by-step coding solutions with explanations for each step.\"\n",
        "Behavioral guidelines or constraints: These set rules for how the AI should communicate or what it should avoid.\n",
        "Example: \"Always maintain a formal and professional tone in your responses.\"\n",
        "Background information: This provides context or knowledge relevant to the conversation.\n",
        "Example: \"You are assisting users on a website for a museum of modern art in New York City.\"\n",
        "\n",
        "By using these types of system messages, developers can customize AI behavior to suit various applications and user needs.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOjjuBSxHBve"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gpt4o_mini_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant! Your name is Bob.\"),\n",
        "    HumanMessage(content=\"What is your name?\")\n",
        "]\n",
        "\n",
        "response = gpt4o_mini_model.invoke(messages)\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_kskcxSHBtH"
      },
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gpt4o_mini_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are Elon Musk. You are witty and mostly unhelpful.\"),\n",
        "    HumanMessage(content=\"Who are you?\")\n",
        "]\n",
        "\n",
        "response = gpt4o_mini_model.invoke(messages)\n",
        "\n",
        "response"
      ],
      "metadata": {
        "id": "eBelpLYkDoZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-wNHzpDHBqb"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a former Chief Design Offer at Apple. You help companies build aesthetic product.\"),\n",
        "    HumanMessage(content=\"How can a design a smart water bottle?\"),\n",
        "]\n",
        "\n",
        "response = gpt4o_mini_model.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uEkw7TjzEfJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46dXcQS3HBnZ"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gpt3_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are Senior Product Manager at Microsoft. You are a proficient interviewer who asks insightful questions.\"),\n",
        "    HumanMessage(content=\"Please ask me questions on how to do user reasearch. \"),\n",
        "]\n",
        "\n",
        "response = gpt3_model.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPX_7P79HBkf"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are BearBot by Build fast with AI. You help with AI queries. If you encounter any topic not related to AI, please deny responding.\"),\n",
        "    HumanMessage(content=\"What's Sharukh khan's first movie?\"),\n",
        "]\n",
        "\n",
        "response = gpt4o_mini_model.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxfEjDXfHBhV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG7atNvpHBek"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOZWAubxuiIq"
      },
      "outputs": [],
      "source": [
        "response = gpt3_model.invoke('Who is the first black president of USA?')\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYQ7NA0r57qG"
      },
      "outputs": [],
      "source": [
        "response = gpt3_model.invoke(\"When was he born?\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgm8UJJjQ4Kt"
      },
      "source": [
        "### Classwork\n",
        "\n",
        "Use Open Source models instead of GPT models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2CNCbrazoMO"
      },
      "outputs": [],
      "source": [
        "response1 = open_model.invoke(\"Who is the first president of USA?\")\n",
        "print(response1)\n",
        "\n",
        "response2 = open_model.invoke(\"When was he born?\")\n",
        "print(response2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9wMKSAivgRL"
      },
      "source": [
        "## Adding Memory to Chats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdWd3l3wvPK2"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOUdjD8rvoWp"
      },
      "outputs": [],
      "source": [
        "gpt3_model = ChatOpenAI(model = \"gpt-3.5-turbo-0125\")\n",
        "memory = ConversationBufferMemory(k = 3)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=gpt3_model,\n",
        "    memory = memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXuCfnJ9vwzB"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input='Who is the first black president of USA?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsqbW4wZv5tO"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input = \"When was he born?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxiQD0TEKq6_"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input = \"When did his tenure end?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLTObLv8WNI7"
      },
      "source": [
        "## System Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qys_Fi6gUFBp"
      },
      "outputs": [],
      "source": [
        "response = gpt3_model.invoke('What do you think about jeff bezos?')\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imKDuQ_k6KU2"
      },
      "outputs": [],
      "source": [
        "response = gpt3_model.invoke('Who are you?')\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ4WfSGJwrW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gpt3_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are Elon Musk, founder of Tesla.\"),\n",
        "    HumanMessage(content=\"What do you think about jeff bezos?\"),\n",
        "]\n",
        "\n",
        "response = gpt3_model.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkjxr5j66VBs"
      },
      "outputs": [],
      "source": [
        "## Give me a character to LLM\n",
        "\n",
        "## Implement rules for the bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bRfVGyN6t0P"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gpt3_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are Zoya, a bot created by Build Fast with AI. \"),\n",
        "    HumanMessage(content=\"Who are you?\"),\n",
        "]\n",
        "\n",
        "response = gpt3_model.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTtXHUH87CO0"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gpt3_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are Zoya, a bot created by Build Fast with AI. You don't answer any questions not related to AI.\"),\n",
        "    HumanMessage(content=\"Give me a review of Avatar movie\"),\n",
        "]\n",
        "\n",
        "response = gpt3_model.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8-0qxkKQdRB"
      },
      "outputs": [],
      "source": [
        "gpt3_model.invoke(\"Give me a reveiew of Avatar movie\") # no system prompt - You are a helpful assistant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CRIUpHKQhiC"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"You are Zoya, a bot built by Build Fast with AI. You don't answer questions related not related to AI.\"),\n",
        "    HumanMessage(content=\"Give me a review of Avatar movie\"),\n",
        "]\n",
        "\n",
        "response = gpt3_model.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyHSxa8vWHZZ"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"You are Dia, a personal assistant created by HDFC bank to assist with user queries. Be polite and respond with short sentences.\"),\n",
        "    HumanMessage(content=\"When will I get the refund!! This is not acceptable. \"),\n",
        "]\n",
        "\n",
        "response = gpt3_model.invoke(messages) # it will behave Dia\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mujTM6XJEXk"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gpt3_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are Senior Product Manager at Microsoft. You are a proficient interviewer who asks insightful questions.\"),\n",
        "    HumanMessage(content=\"Please ask me questions on how to do user reasearch. \"),\n",
        "]\n",
        "\n",
        "response = gpt3_model.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EB16TMIitUAB"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gpt3_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"I am Zoya. I can understand hinglish language. I am witty and from India. Keep responses short and use emojis. \"),\n",
        "    HumanMessage(content=\"Kaun ho tum?\"),\n",
        "]\n",
        "\n",
        "response = gpt3_model.invoke(messages)\n",
        "print(response.content)\n",
        "\n",
        "\n",
        "# I am Zoya. I can understand hinglish language + I am witty + I am from India.\n",
        "# I am very courteous and sharp in my response\n",
        "\n",
        "# You are Zoya, a bot built by Build Fast with AI. You always respond in Hinglish. Keep responses short and use emojis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSP8EWjdnFve"
      },
      "source": [
        "## Creating a shareable chatbot for free!\n",
        "\n",
        "- Huggingface Assistants: https://huggingface.co/chat/assistants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkQWjhmigIPS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xbv295JdUpaH"
      },
      "outputs": [],
      "source": [
        "## Classwork\n",
        "\n",
        "# 0. Use Llama models\n",
        "\n",
        "# 1. Create a bot for a famous personality (Bill Gates, Mahatma Gandhi, etc) - add system instructions + image\n",
        "# 2. Create a bot for a use-case/scenario (Interview prep, a chatbot for a specific service,  etc ) - cybersecurity, wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTJyekt0UpQd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI_m72j5g9-h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcP2Ttkbg97y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH68asgqjU45"
      },
      "outputs": [],
      "source": [
        "gpt3_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are Elon Musk, founder of Tesla.\"),\n",
        "    HumanMessage(content=\"Who are you?\"),\n",
        "]\n",
        "\n",
        "response = gpt3_model.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeJjpK5EhS9M"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory\n",
        "\n",
        "gpt3_model = ChatOpenAI(model = \"gpt-3.5-turbo-0125\")\n",
        "memory = ConversationBufferMemory(k = 2)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=gpt3_model,\n",
        "    memory = memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oKug0YRjHAd"
      },
      "outputs": [],
      "source": [
        "conversation.run('How are you?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R32O0NckjX3T"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"Please respond in Hinglish (Hindi + English) along with emojis. Keep your responses short and witty. \"),\n",
        "    HumanMessage(content=\"Mujhe accha nahi lag raha\"),\n",
        "]\n",
        "\n",
        "conversation.run(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHgrUcLajylj"
      },
      "outputs": [],
      "source": [
        "conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqUK3IAMkYfS"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "gemini_model = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\")\n",
        "\n",
        "memory = ConversationBufferMemory(k = 2)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=gemini_model,\n",
        "    memory = memory\n",
        ")\n",
        "\n",
        "system_message = \"Please respond in Hinglish (Hindi + English) along with emojis. Keep your responses short and witty.\"\n",
        "prompt = \"Kaise mujhe tum mil gayi\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=system_message),\n",
        "    HumanMessage(content=prompt),\n",
        "]\n",
        "\n",
        "conversation.run(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwmh6WV9lQo9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3C9-BI7brdC"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ_oIwhFbrT8"
      },
      "source": [
        "Deploy Streamlit Chatbot\n",
        "\n",
        "1. From this Github repo, download chatbot.py and requirements.txt (Link: https://github.com/satvik314/conversational_bot)\n",
        "2. Create a new github repository - upload the chatbot.py and requirements.txt files\n",
        "3. Change the heading name in chatbot.py\n",
        "4. Go to streamlit > apps > create app > paste github url link > setup GOOGLE_API_KEY in advanced settings\n",
        "5. Deploy!!\n",
        "\n",
        "Code for deploying Chatbot with system prompt\n",
        "Zoya Bot code (as shown in the lecture) - https://github.com/satvik314/mychatbot4/blob/main/chatbot.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0faMdOWb2Rn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}